---
title: |
 <p align="center">
  <img src="https://www.wne.uw.edu.pl/themes/wne/images/en-logo.gif"></p>  
  <h2 style="color:#660033;" align= "center">**Spatial Econometrics Final Project**</h2>
subtitle: <h4 style="color:DimGrey;" align= "center">_Spatial Analysis of Liquor Sales in Virginia and North Carolina_</h4>
author: 
  - <h5 style="color:Grey;" align="center">_Didem Paloglu, 425160_</h5>
  - <h5 style="color:Grey;" align="center">_Huseyin Can Minareci, 417121_</h5>
output:
  html_document:
    self_contained: true
    lib_dir: libs
    theme: spacelab
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: true
    smooth_scroll: true
editor_options: 
  chunk_output_type: console
---



```{r message=FALSE, warning=FALSE, include=FALSE}
# installing necessary packages
library(kableExtra)
library(dplyr)
library(tidyverse)
library(sf)
library(tmap)
library(geojsonio)
library(sp)
library(reshape2)
library(stplanr)
library(leaflet)
library(broom)
library(spdep)
library(maptools)
library(rgdal)
library(shape)
library(RColorBrewer)

```

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```


```{r message=FALSE, warning=FALSE, include=FALSE}
#importing data 

spadata <- readOGR(dsn = ".", layer = "NCVACO Variables")

```


### Requirements 

- introduction to the subject, putting a research hypothesis --> DONE
- description of the data - source, spatial diversity, or changes in time -->> DONE
- specification of the problem / econometric model and expectations
- model estimation and diagnostics / spatial quantitative analysis
- interpretation of results and conclusions


## 1. INTRODUCTION

### 1.1. Aim of the Project

<p style="text-align:justify;">In this project, it is aimed to model liquor demand in Virginia and North Carolina. The original study has been conducted by Mark L. Burkey. With his research, it was aimed to find answer whether the geographical restrictions on the alcohol make any effect on the alcohol-related problems. The results have shown that alcohol restrictions did not make any effect on alcohol-related problems. In our project, we tried to find the answer to our research question: Which factors affect the alcohol demand and how geographical alcohol restrictions changes consumer behaviours. We constructed both traditional regression model with OLS (benchmark model) and also spatial models with SAR & SEM. </p> 


### 1.2. Information About Data Set


<p style="text-align:justify;">In this project, the data set contains 49 variables. The year of the data set is 2003. The variables give information about geographical features of states as well as demographic features. After importing data set, first we need to know the class of the data set. With `class()` function, we can say that the data set is _"SpatialPolygonsDataFrame"_. We can see the head of the data set in below table: </p>

```{r, echo=FALSE}
head(slot(spadata,"data")) %>%
  kable(digits = 2, format = "html", row.names = TRUE, caption = "Head of the Data Set") %>%
  kable_styling(bootstrap_options = c("striped"), font_size = 10) %>%
  row_spec(row = 0, color = "#660033") %>% 
  scroll_box(width = "100%")
```

```{r message=FALSE, warning=FALSE, include=FALSE}
class(spadata)

```

<br>

<p style="text-align:justify;">Before going deep in the data set, the variables and their descriptions are also important to understand and conduct the analysis. Some variables are clear and easy to understand, but some variables are hard to interpret and we need to understand them. Therefore, all variables and necessary descriptions of the variables are provided below:</p>

All Variables:

```{r echo=FALSE}
# variable names
names(spadata)
```

Descriptions:

* **Lon & Lat:** Longitude and latitude of county centroid
* **FIPS, FIPS2:** Code for county (Federal Information Processing Standard)
* **qtystores:** Number of liquor stores in county
* **SALESPC:** Liquor Sales per capita per year, $
* **PCI:** Per capita income
* **COMM15OVP:** % of commuting over 15 minutes to work
* **COLLENRP:** % of people currently enrolled in college
* **SOMECOLLP:** % of people with “some college” or higher education level
* **ARMEDP:** % in armed forces
* **NONWHITEP:** % of nonwhite people
* **UNEMPP:** % of unemployed people
* **ENTRECP** % of employment in entertainment or recreation fields (proxy for tourism areas)
* **PUBASSTP:** % on public assistance of some sort
* **POVPOPP:** % in poverty
* **URBANP:** % of people living in urban areas
* **FOREIGNBP:** % foreign born
* **BAPTISTSP:** % of southern baptist (historically anti-alcohol)
* **ADHERENTSP:** % of adherents of any religion
* **BKGRTOMIX:** Weighted average distance from block group to nearest bar selling liquor
* **COUNTMXBV:** Count of bars selling liquor
* **MXBVSQM:** Bars per square mile
* **BKGRTOABC:** Distance for block group to nearest retail liquor outlet (“ABC stores”)
* **MXBVPPOP18:** Bars per 1,000 people 18 and older
* **DUI1802:** DUI arrests per 1,000 people 18+
* **FVPTHH02:** Offences against families and children (domestic violence) per 1,000 households
* **DC,GA, KY, MD, SC, TN, WV, VA:** Dummy variables for counties bordering other states
* **AREALANDSQ:** Area of county
* **COUNTBKGR:**  Count of block groups in county
* **TOTALPOP:** Population of county
* **POP18OV:** Population of 18+ people in county
* **LABFORCE:** number of people in labor force in county
* **HHOLDS:** number of households in county
* **POP25OV:** Population of 25+ people in county
* **POP16OV:** Population of 16+ people in county

After having information about variables, we can see the summary of the data set. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
summary(spadata)

```
<p style="text-align:justify;">From the summary of the data set, some variables like income and population are seen as in wrong format. So, we need to convert these variables into true format (factor to numeric). </p>

```{r message=FALSE, warning=FALSE}

# converting factor variables to numeric variables

spadata$qtystores <- as.numeric(levels(spadata$qtystores))[spadata$qtystores]
spadata$PCI <- as.numeric(levels(spadata$PCI))[spadata$PCI]
spadata$COUNTMXBV <- as.numeric(levels(spadata$COUNTMXBV))[spadata$COUNTMXBV]
spadata$COUNTBKGR <- as.numeric(levels(spadata$COUNTBKGR))[spadata$COUNTBKGR]
spadata$TOTALPOP <- as.numeric(levels(spadata$TOTALPOP))[spadata$TOTALPOP]
spadata$POP18OV <- as.numeric(levels(spadata$POP18OV))[spadata$POP18OV]
spadata$LABFORCE <- as.numeric(levels(spadata$LABFORCE))[spadata$LABFORCE]
spadata$HHOLDS <- as.numeric(levels(spadata$HHOLDS))[spadata$HHOLDS]
spadata$POP25OV <- as.numeric(levels(spadata$POP25OV))[spadata$POP25OV]
spadata$POP16OV <- as.numeric(levels(spadata$POP16OV))[spadata$POP16OV]
```
Now, all the variables can be seen in the true formats in below table:

```{r echo=FALSE, message=FALSE, warning=FALSE}
str(slot(spadata,"data"))
```

<p style="text-align:justify;"> After variable transformation, the data set is ready for analysis. In the following section, some explonatory data analysis (EDA) will be conducted in order to see the distribution of important factors in the data set.</p>

### 1.3. Explonatory Data Analysis (EDA)

<p style="text-align:justify;">EDA is important tool to see the general picture of the data set. In this section, EDA has been applied as preliminary analysis. First analysis, obviously, to look at the dependent vairable in the model. Liqour sales (SALESPC) is the dependent variable in the data set. The visualization of the liqour sales density in geographic map as below:</p>

```{r echo=FALSE, message=FALSE, warning=FALSE}

variable<-spadata$SALESPC
maxy<-300
breaks<-c(0, 50, 100, 150, 200, 250, 300) # used in the legend 
nclr<-7
plotclr<-brewer.pal(nclr, "Reds") # from the RColorBrewer package 
fillRed<-colorRampPalette(plotclr) # from the grDevices package 
colcode<-fillRed(maxy)[round(variable) + 1] # fillRed is a function 
plot(spadata, col=colcode , lwd=1,border="gray70") 

colorlegend(posy=c(0.05,0.9), posx=c(0.9,0.92), col=fillRed(maxy), zlim=c(0, maxy), zval=breaks, main.cex=0.9) # from the shape:: package

title(main="Liqour Sales Per Capita Per Year ($)\n in Virginia and North Carolina")
```

<br> 

<p style="text-align:justify;">From the figure, the top map represents Virginia and bottom map represents North Carolina. We can see that highest sales have occured in East North Carolina. Moreover, for both states the liqour sales are generally low (mostly between 0-150$).</p>

***

Second insight 

```{r}
library(sf)
spadata.sf <- st_read("NCVACO Variables.shp")
spadata.sf<- st_transform(spadata.sf, CRS("+proj=longlat +datum=NAD83")) 


```

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot() +
  geom_sf(spadata.sf, mapping = aes(geometry=geometry, fill = TOTALPOP)) +
  labs(title = "Population Density in Virginia and North Carolina",
       fill = "Total Population") +
  annotate("text", x = -83, y = 39, size = 5, 
           color = "red", alpha = 0.4, label = "Virginia") +
  annotate("text", x = -82, y = 34, size = 5, 
           color = "red", alpha = 0.4, label = "North Carolina") +
  theme(panel.background = element_blank())

```


### Clustering
### OLS (Benchmark model)
### SAR / SEM 
### Diagnostic Tests
### Conclusion

<!-- CAN'S PART -->

### preparing spatial weights matrix
Queen criterion: two units are close if they share a side or an edge.
Rook criterion: two units are close to one another if they share a side


```{r}
nbrqueen <- poly2nb(spadata, row.names = spadata$FIPS)
nbrrook  <- poly2nb(spadata, queen=FALSE) 
```

```{r}
moranTest <- moran.test(spadata$SALESPC, nb2listw(nbrqueen))
moranTest
```

### OLS (Benchmark model)

```{r}
ols <- lm(SALESPC ~ DUI1802 + SOMECOLLP + BKGRTOABC + BAPTISTSP + BKGRTOMIX + ENTRECP + NONWHITEP + UNEMPP + PCI + URBANP + FVPTHH02, data = spadata)
summary(ols)
```


```{r}

# diagnostics of linear model
library(lmtest)
bptest(ols) # heteroscedasticity test (H1) /homoscedast…(H0)

```

P-value is 0.001 so we reject H0 homoscedasticity which means we have homoscedasticity.



```{r}

# Ramsey’s test for functional form
# H1: when non-linear variables (like powers of the variables) should be included then model is mis-specified
resettest(ols, power=2, type="regressor") 	
```

p-value is 0.02517 so we reject H0, This indicates that the functional form is correct and our model does not suffer from omitted variables.

### Moran Correlation Test

H0: No spatial correlation in the residuals


```{r}
lmMoranTest <- lm.morantest(ols,nb2listw(nbrqueen)) # are residuals spatially random?
lmMoranTest

```

p-value is very small so we have to reject null hypothesis and Moran's Statistic is 0.19 which means that there is a significant evidence that positive spatial correlation exists between the residuals and we should use a spatial model.

# Moran scatterplot
```{r}
# preparing the data
x<-spadata$DUI1802 # variable selection
zx<-as.data.frame(scale(x))  #standardization of variable

# Moran scatterplot – automatic version
moran.plot(zx$V1, nb2listw(nbrqueen), pch=19, labels=as.character(spadata$NAME))

```


```{r}
# test join.count for residuals (positive vs. negative)
resid<-factor(cut(res, breaks=c(-100, 0, 100), labels=c("negative","positive")))
joincount.test(resid, nb2listw(nbrqueen))
```


```{r}

# spatial distribution of OLS residuals
summary(ols$residuals)
res<-ols$residuals
brks<-c(min(res), mean(res)-sd(res), mean(res), mean(res)+sd(res), max(res))
cols<-c("steelblue4","lightskyblue","thistle1","plum3")
plot(spadata, col=cols[findInterval(res,brks)])
#plot(woj, add=TRUE, lwd=2)
title(main="Spatial Distribution of OLS Residuals")
legend("bottomleft", legend=c("<mean-sd", "(mean-sd, mean)", "(mean, mean+sd)", ">mean+sd"), leglabs(brks1), fill=cols, bty="n")


```


Emin degilim buna gerek var mi ama dursun simdilik burada :D
 ```{r}
# # OLS model
# model<-glm(DUI1802 ~ SALESPC + COLLENRP + BKGRTOABC + BAPTISTSP + BKGRTOMIX + ENTRECP, data = spadata)
# summary(model)
# ```
# ```{r}
# SRMSE<-sqrt(sum((model$fitted.values-spadata$DUI1802)^ 2)/ dim(spadata)[1]) / (mean(spadata$DUI1802))
# SRMSE
# ```

# ```{r}
# plot(spadata$SALESPC, spadata$DUI1802)
# points(spadata$SALESPC, model$fitted.values, col="red")
# abline(h=1, lty=3)
# title(main="OLS, multinominal, fitted values")
 ```

what next...


### SAR /SEM 

```{r}
names(spadata) 
```


```{r}

str(slot(spadata,"data"))


```
### Diagnostic Tests


### Conclusion





